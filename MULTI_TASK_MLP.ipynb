{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvRxZNmFVhNK"
      },
      "source": [
        "# **Reading User's Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "I8WHYRQi-iZZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D-XRV-M9_DZr"
      },
      "outputs": [],
      "source": [
        "def read_data(uuids):\n",
        "\n",
        "\n",
        "   user_data_file='%s.features_labels.csv'%uuids;\n",
        "   df = pd.read_csv(user_data_file);\n",
        "\n",
        "   # The first column should be timestamp:\n",
        "   assert df.columns[0] == 'timestamp';\n",
        "   #  The last column should be label_source:\n",
        "   assert df.columns[-1] == 'label_source';\n",
        "   for (ci,col) in enumerate(df.columns):\n",
        "        if col.startswith('label:'):\n",
        "            first_label_ind = ci;\n",
        "            break;\n",
        "        pass;\n",
        "   df.columns = df.columns.str.replace('label:', '')\n",
        "\n",
        "   # Feature columns come after timestamp and before the labels:\n",
        "   feature_names = df.columns[1:first_label_ind];\n",
        "   # Then come the labels, till the one-before-last column:\n",
        "   label_names = df.columns[first_label_ind:-1];\n",
        "\n",
        "   n_features = len(feature_names);\n",
        "   timestampe= df.iloc[:,0]\n",
        "\n",
        "   X = df.iloc[:,1:(n_features+1)]\n",
        "   X = X.fillna(0)\n",
        "   trinary_labels_mat = df.iloc[:,(n_features+1):-1]; # This should have values of either 0., 1. or NaN\n",
        "   trinary_labels_mat = trinary_labels_mat.fillna(0)\n",
        "   \n",
        "   #Deleting the columns:\n",
        "\n",
        "   #for col in trinary_labels_mat.columns:\n",
        "   #    if trinary_labels_mat[col].sum(axis = 0)<=0 :\n",
        "   #       del trinary_labels_mat[col]\n",
        "\n",
        "   M = pd.isna(trinary_labels_mat)\n",
        "   Y = np.where(M,0,trinary_labels_mat) > 0.;\n",
        "\n",
        "   return X , Y , M , trinary_labels_mat, feature_names, label_names, timestampe,n_features ;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RJrtz5Px_Lx8"
      },
      "outputs": [],
      "source": [
        "uuids='0E6184E1-90C0-48EE-B25A-F1ECB7B9714E';\n",
        "(X , Y , M , trinary_labels_mat, feature_names, label_names, timestampe, n_features) = read_data(uuids);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "Bp2GU52ybgec",
        "outputId": "35d574be-bc31-4128-fb74-dd1618b4f9b5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LYING_DOWN</th>\n",
              "      <th>SITTING</th>\n",
              "      <th>FIX_walking</th>\n",
              "      <th>FIX_running</th>\n",
              "      <th>BICYCLING</th>\n",
              "      <th>SLEEPING</th>\n",
              "      <th>LAB_WORK</th>\n",
              "      <th>IN_CLASS</th>\n",
              "      <th>IN_A_MEETING</th>\n",
              "      <th>LOC_main_workplace</th>\n",
              "      <th>OR_indoors</th>\n",
              "      <th>OR_outside</th>\n",
              "      <th>IN_A_CAR</th>\n",
              "      <th>ON_A_BUS</th>\n",
              "      <th>DRIVE_-_I_M_THE_DRIVER</th>\n",
              "      <th>DRIVE_-_I_M_A_PASSENGER</th>\n",
              "      <th>LOC_home</th>\n",
              "      <th>FIX_restaurant</th>\n",
              "      <th>PHONE_IN_POCKET</th>\n",
              "      <th>OR_exercise</th>\n",
              "      <th>COOKING</th>\n",
              "      <th>SHOPPING</th>\n",
              "      <th>STROLLING</th>\n",
              "      <th>DRINKING__ALCOHOL_</th>\n",
              "      <th>BATHING_-_SHOWER</th>\n",
              "      <th>CLEANING</th>\n",
              "      <th>DOING_LAUNDRY</th>\n",
              "      <th>WASHING_DISHES</th>\n",
              "      <th>WATCHING_TV</th>\n",
              "      <th>SURFING_THE_INTERNET</th>\n",
              "      <th>AT_A_PARTY</th>\n",
              "      <th>AT_A_BAR</th>\n",
              "      <th>LOC_beach</th>\n",
              "      <th>SINGING</th>\n",
              "      <th>TALKING</th>\n",
              "      <th>COMPUTER_WORK</th>\n",
              "      <th>EATING</th>\n",
              "      <th>TOILET</th>\n",
              "      <th>GROOMING</th>\n",
              "      <th>DRESSING</th>\n",
              "      <th>AT_THE_GYM</th>\n",
              "      <th>STAIRS_-_GOING_UP</th>\n",
              "      <th>STAIRS_-_GOING_DOWN</th>\n",
              "      <th>ELEVATOR</th>\n",
              "      <th>OR_standing</th>\n",
              "      <th>AT_SCHOOL</th>\n",
              "      <th>PHONE_IN_HAND</th>\n",
              "      <th>PHONE_IN_BAG</th>\n",
              "      <th>PHONE_ON_TABLE</th>\n",
              "      <th>WITH_CO-WORKERS</th>\n",
              "      <th>WITH_FRIENDS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122701</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122702</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122703</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122704</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122705</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>122706 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        LYING_DOWN  SITTING  ...  WITH_CO-WORKERS  WITH_FRIENDS\n",
              "0              0.0      1.0  ...              0.0           0.0\n",
              "1              0.0      1.0  ...              0.0           0.0\n",
              "2              0.0      1.0  ...              0.0           0.0\n",
              "3              0.0      1.0  ...              0.0           0.0\n",
              "4              0.0      1.0  ...              0.0           0.0\n",
              "...            ...      ...  ...              ...           ...\n",
              "122701         0.0      0.0  ...              0.0           0.0\n",
              "122702         0.0      0.0  ...              0.0           0.0\n",
              "122703         0.0      0.0  ...              0.0           0.0\n",
              "122704         0.0      0.0  ...              0.0           0.0\n",
              "122705         0.0      0.0  ...              0.0           0.0\n",
              "\n",
              "[122706 rows x 51 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trinary_labels_mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKhSNL22XFmp"
      },
      "source": [
        "**Deleting the missing examples**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKxHg-UEU6Sq"
      },
      "outputs": [],
      "source": [
        "trinary_labels_mat['sum'] =np.sum(trinary_labels_mat, axis=1)\n",
        "# (  if (trinary_labels_mat['sum'] == null): trinary_labels_mat)\n",
        "trinary_labels_mat=trinary_labels_mat[trinary_labels_mat['sum']!=0]\n",
        "trinary_labels_mat=trinary_labels_mat.drop(['sum'],axis=1)\n",
        "df = pd.concat([trinary_labels_mat,X ], axis=1, join='inner')\n",
        "X=df.iloc[:,51:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cXBRve6YCC-"
      },
      "outputs": [],
      "source": [
        "row_sum = np.sum(trinary_labels_mat, axis=1)\n",
        "print(row_sum)\n",
        "#yyy= row_sum.value_counts()[0]\n",
        "#print(yyy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjyJnLyxMt8a"
      },
      "outputs": [],
      "source": [
        "print(X.shape);\n",
        "print(Y.shape);\n",
        "print(M.shape);\n",
        "print(trinary_labels_mat);\n",
        "print(timestampe.shape);\n",
        "print(label_names.shape);\n",
        "print(feature_names.shape);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka_6NgPOXlCT"
      },
      "source": [
        "**Sum of labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z8t3UoEMFp6"
      },
      "outputs": [],
      "source": [
        "n_examples_per_label = np.sum(trinary_labels_mat,axis=0);\n",
        "labels_and_counts = zip(label_names,n_examples_per_label);\n",
        "sorted_labels_and_counts = sorted(labels_and_counts,reverse=True,key=lambda pair:pair[1]);\n",
        "print (\"How many examples does this user have for each contex-label:\");\n",
        "print (\"-\"*50);\n",
        "for (label,count) in sorted_labels_and_counts:\n",
        "    print (\"label %s - %d minutes\" % (label,count));\n",
        "    pass;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_Fs7Sm7YJrJ"
      },
      "source": [
        "**Get sensor names from features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQrVGnJy_MAO"
      },
      "outputs": [],
      "source": [
        "def get_sensor_names_from_features(feature_names):\n",
        "    feat_sensor_names = np.array([None for feat in feature_names]);\n",
        "    for (fi,feat) in enumerate(feature_names):\n",
        "        if feat.startswith('raw_acc'):\n",
        "            feat_sensor_names[fi] = 'Acc';\n",
        "            pass;\n",
        "        elif feat.startswith('proc_gyro'):\n",
        "            feat_sensor_names[fi] = 'Gyro';\n",
        "            pass;\n",
        "        elif feat.startswith('raw_magnet'):\n",
        "            feat_sensor_names[fi] = 'Magnet';\n",
        "            pass;\n",
        "        elif feat.startswith('watch_acceleration'):\n",
        "            feat_sensor_names[fi] = 'WAcc';\n",
        "            pass;\n",
        "        elif feat.startswith('watch_heading'):\n",
        "            feat_sensor_names[fi] = 'Compass';\n",
        "            pass;\n",
        "        elif feat.startswith('location'):\n",
        "            feat_sensor_names[fi] = 'Loc';\n",
        "            pass;\n",
        "        elif feat.startswith('location_quick_features'):\n",
        "            feat_sensor_names[fi] = 'Loc';\n",
        "            pass;\n",
        "        elif feat.startswith('audio_naive'):\n",
        "            feat_sensor_names[fi] = 'Aud';\n",
        "            pass;\n",
        "        elif feat.startswith('audio_properties'):\n",
        "            feat_sensor_names[fi] = 'AP';\n",
        "            pass;\n",
        "        elif feat.startswith('discrete'):\n",
        "            feat_sensor_names[fi] = 'PS';\n",
        "            pass;\n",
        "        elif feat.startswith('lf_measurements'):\n",
        "            feat_sensor_names[fi] = 'LF';\n",
        "            pass;\n",
        "        else:\n",
        "            raise ValueError(\"!!! Unsupported feature name: %s\" % feat);\n",
        "\n",
        "        pass;\n",
        "\n",
        "    return feat_sensor_names;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gj6eXqza_i7Q"
      },
      "outputs": [],
      "source": [
        "feat_sensor_names = get_sensor_names_from_features(feature_names);\n",
        "\n",
        "for (fi,feature) in enumerate(feature_names):\n",
        "    print(\"%3d) %s %s\" % (fi,feat_sensor_names[fi].ljust(10),feature));\n",
        "    pass;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lebZx5FtYc8K"
      },
      "source": [
        "# **Oversampling technique of minority labels (MLSMOTE)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-A6gcoM_3sx"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "def get_tail_label(df):\n",
        "    \"\"\"\n",
        "    Give tail label colums of the given target dataframe\n",
        "    \n",
        "    args\n",
        "    df: pandas.DataFrame, target label df whose tail label has to identified\n",
        "    \n",
        "    return\n",
        "    tail_label: list, a list containing column name of all the tail label\n",
        "    \"\"\"\n",
        "    columns = df.columns\n",
        "    n = len(columns)\n",
        "    irpl = np.zeros(n)\n",
        "    for column in range(n):\n",
        "         irpl[column] = df[columns[column]].value_counts()[1]\n",
        "    irpl = max(irpl)/irpl\n",
        "    print(irpl)\n",
        "    mir = np.mean(irpl, axis=0)\n",
        "    print(mir)\n",
        "    tail_label = []\n",
        "    for i in range(n):\n",
        "        if irpl[i] > mir:\n",
        "          tail_label.append(columns[i])\n",
        "    return tail_label\n",
        "\n",
        "def get_index(df):\n",
        "  \"\"\"\n",
        "  give the index of all tail_label rows\n",
        "  args\n",
        "  df: pandas.DataFrame, target label df from which index for tail label has to identified\n",
        "    \n",
        "  return\n",
        "  index: list, a list containing index number of all the tail label\n",
        "  \"\"\"\n",
        "  tail_labels = get_tail_label(df)\n",
        "  print(tail_labels)\n",
        "\n",
        "  index = set()\n",
        "  for tail_label in tail_labels:\n",
        "    sub_index = set(df[df[tail_label]==1].index)\n",
        "    index = index.union(sub_index)\n",
        "  return list(index)\n",
        "\n",
        "def get_minority_instace(X, y):\n",
        "    \"\"\"\n",
        "    Give minority dataframe containing all the tail labels\n",
        "    \n",
        "    args\n",
        "    X: pandas.DataFrame, the feature vector dataframe\n",
        "    y: pandas.DataFrame, the target vector dataframe\n",
        "    \n",
        "    return\n",
        "    X_sub: pandas.DataFrame, the feature vector minority dataframe\n",
        "    y_sub: pandas.DataFrame, the target vector minority dataframe\n",
        "    \"\"\"\n",
        "    index = get_index(y)\n",
        "    X_sub = X[X.index.isin(index)].reset_index(drop = True)\n",
        "    y_sub = y[y.index.isin(index)].reset_index(drop = True)\n",
        "    return X_sub, y_sub\n",
        "\n",
        "def nearest_neighbour(X):\n",
        "    \"\"\"\n",
        "    Give index of 5 nearest neighbor of all the instance\n",
        "    \n",
        "    args\n",
        "    X: np.array, array whose nearest neighbor has to find\n",
        "    \n",
        "    return\n",
        "    indices: list of list, index of 5 NN of each element in X\n",
        "    \"\"\"\n",
        "    nbs=NearestNeighbors(n_neighbors=5,metric='euclidean',algorithm='kd_tree').fit(X)\n",
        "    euclidean,indices= nbs.kneighbors(X)\n",
        "    return indices\n",
        "\n",
        "def MLSMOTE(X,y, n_sample):\n",
        "    \"\"\"\n",
        "    Give the augmented data using MLSMOTE algorithm\n",
        "    \n",
        "    args\n",
        "    X: pandas.DataFrame, input vector DataFrame\n",
        "    y: pandas.DataFrame, feature vector dataframe\n",
        "    n_sample: int, number of newly generated sample\n",
        "    \n",
        "    return\n",
        "    new_X: pandas.DataFrame, augmented feature vector data\n",
        "    target: pandas.DataFrame, augmented target vector data\n",
        "    \"\"\"\n",
        "    indices2 = nearest_neighbour(X)\n",
        "    n = len(indices2)\n",
        "    new_X = np.zeros((n_sample, X.shape[1]))\n",
        "    target = np.zeros((n_sample, y.shape[1]))\n",
        "    for i in range(n_sample):\n",
        "        reference = random.randint(0,n-1)\n",
        "        neighbour = random.choice(indices2[reference,1:])\n",
        "        all_point = indices2[reference]\n",
        "        nn_df = y[y.index.isin(all_point)]\n",
        "        ser = nn_df.sum(axis = 0, skipna = True)\n",
        "        target[i] = np.array([1 if val>2 else 0 for val in ser])\n",
        "        ratio = random.random()\n",
        "        gap = X.loc[reference,:] - X.loc[neighbour,:]\n",
        "        new_X[i] = np.array(X.loc[reference,:] + ratio * gap)\n",
        "    new_X = pd.DataFrame(new_X, columns=X.columns)\n",
        "    target = pd.DataFrame(target, columns=y.columns)\n",
        "    new_X = pd.concat([X, new_X], axis=0)\n",
        "    target = pd.concat([y, target], axis=0)\n",
        "    return new_X, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO6BBW5CQttc"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    main function to use the MLSMOTE\n",
        "\"\"\"\n",
        "X_sub, y_sub = get_minority_instace(X, trinary_labels_mat )   #Getting minority instance of that datframe\n",
        "X_res,y_res =MLSMOTE(X_sub, y_sub, 101176 )     #Applying MLSMOTE to augment the dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuRBWRRoZG2D"
      },
      "source": [
        "**Adding LeakyRelu activation function for MLPClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlMIeCgSAFfg"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network.multilayer_perceptron import(ACTIVATIONS, DERIVATIVES, MLPClassifier)\n",
        "#import numpy as np\n",
        "def leakyrelu(X, alpha =0.1):\n",
        "    np.clip(X, alpha*X, np.finfo(X.dtype).max, out=X)   \n",
        "    return X\n",
        "\n",
        "def inplace_leakyrelu_derivative(Z, delta, alpha=0.01):\n",
        "    delta[Z < 0] = alpha\n",
        "\n",
        "\n",
        "ACTIVATIONS['leakyrelu']= leakyrelu\n",
        "DERIVATIVES['leakyrelu']= inplace_leakyrelu_derivative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd9x8UIJZqgL"
      },
      "source": [
        "**Standardization of Features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WDmuPY9AMRO"
      },
      "outputs": [],
      "source": [
        "def project_features_to_selected_sensors(X,feat_sensor_names,sensors_to_use):\n",
        "    use_feature = np.zeros(len(feat_sensor_names),dtype=bool);\n",
        "    for sensor in sensors_to_use:\n",
        "        is_from_sensor = (feat_sensor_names == sensor);\n",
        "        use_feature = np.logical_or(use_feature,is_from_sensor);\n",
        "\n",
        "        pass;\n",
        "    \n",
        "    X = X.iloc[:,use_feature];\n",
        "    return X;\n",
        "\n",
        "def estimate_standardization_params(X_train):\n",
        "    mean_vec = np.nanmean(X_train,axis=0);\n",
        "    \n",
        "    std_vec = np.nanstd(X_train,axis=0);\n",
        "    return (mean_vec,std_vec);\n",
        "\n",
        "def standardize_features(X,mean_vec,std_vec):\n",
        "    # Subtract the mean, to centralize all features around zero:\n",
        "    X_centralized = X - mean_vec.reshape((1,-1));\n",
        "    # Divide by the standard deviation, to get unit-variance for all features:\n",
        "    # * Avoid dividing by zero, in case some feature had estimate of zero variance\n",
        "    normalizers = np.where(std_vec > 0., std_vec, 1.).reshape((1,-1));\n",
        "    X_standard = X_centralized / normalizers;\n",
        "    return X_standard;\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9afHC7YiaG_k"
      },
      "source": [
        "**Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqrQorUVARLR"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def min_max_scaler(A):\n",
        "  scaler = minmax_scale(A,feature_range=(-1,1), axis=1)\n",
        "  #scaler = MinMaxScaler()\n",
        "  #scaler = scaler.fit_transform(A)\n",
        "  #scaler =scaler.transform(A)\n",
        "  return scaler;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npaljlK9aYn-"
      },
      "source": [
        "# **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrgbS7h5AaeM"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score ,GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "\n",
        "def train_model(X_train,Y_train,feat_sensor_names,label_names,sensors_to_use):\n",
        "     \n",
        "    X_train = project_features_to_selected_sensors(X_train,feat_sensor_names,sensors_to_use);\n",
        "    \n",
        "    #X_train = min_max_scaler(X_train)\n",
        "    \n",
        "    (mean_vec,std_vec) = estimate_standardization_params(X_train);\n",
        "    X_train = standardize_features(X_train,mean_vec,std_vec);\n",
        "    \n",
        "\n",
        "    X_train[np.isnan(X_train)] = 0.;\n",
        "\n",
        "    #print(\"== Training with %d examples. For label we have %d positive and %d negative examples.\" % \\\n",
        "     #     (len(trinary_labels_mat),sum(y),sum(np.logical_not(y))) );\n",
        "   \n",
        "   \n",
        "   #\"'Logistic regression model:'\n",
        "   #'Parameter Tuning for Logistic regression:'\n",
        "   #parametars= {'C':[0.000001,0.00001,0.0001,0.001,0.01,0.1,1,10,100]},\n",
        "\n",
        "   #clf = LogisticRegression(class_weight='balanced',max_iter=200)\n",
        "    \n",
        "\n",
        "   #'Spliting the Data into Train and Test set:'\n",
        "   #X_train1, X_test1, Y_train1, Y_test1 = train_test_split(x_train, Y_train, test_size= 0.3)\n",
        "    \n",
        "   #'Parameter Tuning for MLPClassifier:'\n",
        "\n",
        "   #parameters = {'hidden_layer_sizes':[(2,),(4,),(8,),(16,),(32,)], \n",
        "                  #'alpha':[0.0001,0.0005,0.001,0.005,0.01,0.05,0.1]}\n",
        "   #'Gridsearch:'\n",
        "   #grid_search = GridSearchCV(clf, parameters, cv=5)\n",
        "   #grid_search.fit(X_train1,Y_train1);\n",
        "   #print(grid_search.best_params_)\n",
        "    \n",
        "\n",
        "   #'principal component analysis (PCA):'\n",
        "   # from sklearn.decomposition import PCA\n",
        "   # pca = PCA(n_components=128)\n",
        "   # pca.fit(X_train)\n",
        "   # X_pca = pca.transform(X_train)\n",
        "   # print(X_train.shape)\n",
        "   # print(X_pca.shape)\n",
        "\n",
        "   #'Muli-task MLP:'\n",
        "    clf = MLPClassifier (hidden_layer_sizes = (2,), activation='leakyrelu',random_state=0, max_iter = 40, solver = 'sgd', \n",
        "                       momentum=0.5, learning_rate='invscaling', alpha=0.01,power_t=0.5, learning_rate_init=0.1, batch_size=300)\n",
        "   #clf_model=clf.fit(X_pca, Y_train)\n",
        "    clf_model=clf.fit(X_train, Y_train)\n",
        "    \n",
        "   #'MLP per label:'\n",
        "   #clf_out = MultiOutputClassifier(clf)\n",
        "   #clf_model = clf_out.fit(X_train,Y_train) \n",
        "   \n",
        "\n",
        "    model = {\\\n",
        "            'sensors_to_use':sensors_to_use,\\\n",
        "            'mean_vec':mean_vec,\\\n",
        "            'std_vec':std_vec,\\\n",
        "            'clf_model':clf_model};\n",
        "    return model;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxvnzdxLqfed"
      },
      "outputs": [],
      "source": [
        "print(X.shape)\n",
        "print(trinary_labels_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gGzPKg1Ah6W"
      },
      "outputs": [],
      "source": [
        "sensors_to_use = ['Acc','WAcc','Gyro','Loc','Aud','PS'];\n",
        "\n",
        "model = train_model(X,trinary_labels_mat,feat_sensor_names,label_names,sensors_to_use);\n",
        "#model = train_model(X_res,y_res,feat_sensor_names,label_names,sensors_to_use);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z7BFLXlG2Cs"
      },
      "outputs": [],
      "source": [
        "def test_model(X_test,Y_test,feat_sensor_names,label_names,model):\n",
        "    # Project the feature matrix to the features from the sensors that the classifier is based on:\n",
        "    X_test = project_features_to_selected_sensors(X_test,feat_sensor_names,model['sensors_to_use']);\n",
        "    print(\"== Projected the features to %d features from the sensors: %s\" % (X_test.shape[1],', '.join(model['sensors_to_use'])));\n",
        "    \n",
        "    # We should standardize the features the same way the train data was standardized:\n",
        "    \n",
        "    (mean_vec,std_vec) = estimate_standardization_params(X_test);\n",
        "    X_test = standardize_features(X_test,mean_vec,std_vec);\n",
        "    \n",
        "    #X_test = min_max_scaler(X_test)\n",
        "    \n",
        "    y = Y_test;\n",
        "    print(y.shape)\n",
        "\n",
        "    # Do the same treatment for missing features as done to the training data:\n",
        "    X_test[np.isnan(X_test)] = 0.;\n",
        "    \n",
        "    #print(\"== Testing with %d examples. For label '%s' we have %d positive and %d negative examples.\" % \\\n",
        "         # (len(y),get_label_pretty_name(label_names),sum(y),sum(np.logical_not(y))) );\n",
        "    \n",
        "    # Preform the prediction:\n",
        "    y_pred = model['clf_model'].predict(X_test);\n",
        "    \n",
        "    #from sklearn.metrics import multilabel_confusion_matrix\n",
        "    #confusion_matrix= multilabel_confusion_matrix(y, y_pred)\n",
        "    #print (confusion_matrix)\n",
        "    # Naive accuracy (correct classification rate):\n",
        "    accuracy = np.mean(y_pred == y);\n",
        "    accuracy=np.mean(accuracy)\n",
        "\n",
        "    y = np.array(y);\n",
        "    y_pred= np.array(y_pred);\n",
        "\n",
        "    # Count occorrences of true-positive, true-negative, false-positive, and false-negative:\n",
        "    tp = np.sum(np.logical_and(y_pred,y));\n",
        "    tn = np.sum(np.logical_and(np.logical_not(y_pred),np.logical_not(y)));\n",
        "    fp = np.sum(np.logical_and(y_pred,np.logical_not(y)));\n",
        "    fn = np.sum(np.logical_and(np.logical_not(y_pred),y));\n",
        "    \n",
        "    # Sensitivity (=recall=true positive rate) and Specificity (=true negative rate):\n",
        "    sensitivity = float(tp) / (tp+fn);\n",
        "    specificity = float(tn) / (tn+fp);\n",
        "    \n",
        "    # Balanced accuracy is a more fair replacement for the naive accuracy:\n",
        "    balanced_accuracy = (sensitivity + specificity) / 2.;\n",
        "    \n",
        "    # Precision:\n",
        "    # Beware from this metric, since it may be too sensitive to rare labels.\n",
        "    # In the ExtraSensory Dataset, there is large skew among the positive and negative classes,\n",
        "    # and for each label the pos/neg ratio is different.\n",
        "    # This can cause undesirable and misleading results when averaging precision across different labels.\n",
        "    precision = float(tp) / (tp+fp);\n",
        "\n",
        "    print(\"-\"*10);\n",
        "    print('Accuracy*:         %.2f' % accuracy);\n",
        "    print('Sensitivity (TPR): %.2f' % sensitivity);\n",
        "    print('Specificity (TNR): %.2f' % specificity);\n",
        "    print('Balanced accuracy: %.2f' % balanced_accuracy);\n",
        "    print('Precision**:       %.2f' % precision);\n",
        "    print(\"-\"*10);\n",
        "\n",
        "\n",
        "    return;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bQO26-dIrml",
        "outputId": "aec28e1b-7e9a-4fd6-c096-3595c096ff02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Projected the features to 175 features from the sensors: Acc, WAcc, Gyro, Loc, Aud, PS\n",
            "(101176, 51)\n",
            "----------\n",
            "Accuracy*:         0.95\n",
            "Sensitivity (TPR): 0.45\n",
            "Specificity (TNR): 0.99\n",
            "Balanced accuracy: 0.72\n",
            "Precision**:       0.77\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "test_model(X,trinary_labels_mat,feat_sensor_names,label_names,model);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_x1Lv7koSPF"
      },
      "source": [
        "**Reading new User's Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiMHwqX0hn8G"
      },
      "outputs": [],
      "source": [
        "uuiids='fold_4_test';\n",
        "(X1 , Y1 , M1, trinary_labels_mat_test, feature_names1, label_names1, timestampe1, n_features) = read_data(uuiids);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJFJCy1ZTFOh",
        "outputId": "ea5bc104-f4cd-4439-e3f8-9d3047a46b71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((29137, 225), (29137, 51))"
            ]
          },
          "execution_count": 258,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X1.shape , trinary_labels_mat_test.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1qeE-AnlP6M"
      },
      "outputs": [],
      "source": [
        "trinary_labels_mat_test['sum'] =np.sum(trinary_labels_mat_test, axis=1)\n",
        "# (  if (trinary_labels_mat['sum'] == null): trinary_labels_mat)\n",
        "trinary_labels_mat_test=trinary_labels_mat_test[trinary_labels_mat_test['sum']!=0]\n",
        "trinary_labels_mat_test=trinary_labels_mat_test.drop(['sum'],axis=1)\n",
        "df = pd.concat([trinary_labels_mat_test,X1 ], axis=1, join='inner')\n",
        "X1=df.iloc[:,51:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcwaYW6cohFe"
      },
      "source": [
        "**Testing on new User's data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TszPuNIwiQhj",
        "outputId": "e283a904-b194-4aa6-f079-5266a41659ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Projected the features to 175 features from the sensors: Acc, WAcc, Gyro, Loc, Aud, PS\n",
            "(29137, 51)\n",
            "----------\n",
            "Accuracy*:         0.95\n",
            "Sensitivity (TPR): 0.47\n",
            "Specificity (TNR): 0.99\n",
            "Balanced accuracy: 0.73\n",
            "Precision**:       0.74\n",
            "----------\n",
            "(29137, 225) (29137, 51)\n"
          ]
        }
      ],
      "source": [
        "test_model(X1,trinary_labels_mat_test,feat_sensor_names,label_names,model);\n",
        "print(X1.shape, Y1.shape)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "8def5fc1285d5067c620921f219f73286c0282b6229a1c278fdbd9aeef894e51"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
